<!DOCTYPE html><html><head><meta charset="utf-8" /><title>Scikit-learn で線形回帰 - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="tV0WBGc2eEuUIc2nNR31b8KGFgNYZkZnj36hOQH6ZQED3sM6yfhDF/VfISjg8im0CIvnkn0T/028l3MMOLM+WA==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/style-93c10f153c2288070357952f30807154.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-article-bundle-fc3ddf2a543bd826a67f1b52a295f146.min.js" defer="defer"></script><meta name="twitter:card" content="summary_large_image"><meta content="@Qiita" name="twitter:site" /><meta content="@0NE_shoT_" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="Scikit-learn で線形回帰 - Qiita"><meta property="og:image" content="https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-1.2.2&amp;w=1200&amp;mark=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D380%26txt%3DScikit-learn%2520%25E3%2581%25A7%25E7%25B7%259A%25E5%25BD%25A2%25E5%259B%259E%25E5%25B8%25B0%26txt-color%3D%2523333%26txt-font%3DHiragino%2520Sans%2520W6%26txt-size%3D54%26txt-clip%3Dellipsis%26txt-align%3Dcenter%252Cmiddle%26s%3D9de9ec2f33b8b6dc73d1d09231d23753&amp;mark-align=center%2Cmiddle&amp;blend=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D500%26txt%3D%25400NE_shoT_%26txt-color%3D%2523333%26txt-font%3DHiragino%2520Sans%2520W6%26txt-size%3D45%26txt-align%3Dright%252Cbottom%26s%3D812515090497353474e8a1c5ba33624d&amp;blend-align=center%2Cmiddle&amp;blend-mode=normal&amp;s=748fd9192e28c33230ed6f66c4b073a2"><meta property="og:description" content="

はじめに

売り上げなどの数量（連続値をとる目的変数）を予測するのに役立つのが回帰です。この記事では、特に目的変数と説明変数の関係をモデル化する一つの方法である線形回帰をScikit-learnライブラリを使って行う方法について、..."><meta content="https://qiita.com/0NE_shoT_/items/08376b08783cd554b02e" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="Python,機械学習,scikit-learn" name="keywords" /><style data-styled="true" data-styled-version="5.0.1">.iytOeR{display:inline-block;border:2px solid #ccc;font-size:1.4rem;padding:4px 0;text-align:center;cursor:pointer;width:100%;background-color:#fff;color:#333;border-color:#ddd;font-weight:bold;}
.iytOeR:hover{border-color:#adadad;background-color:#e6e6e6;color:#333;}
data-styled.g8[id="UserFollowButton-sc-1hmm0rc-0"]{content:"iytOeR,"}
.pFoNU{display:inline-block;vertical-align:middle;height:12px;width:12px;fill:#777;}
data-styled.g9[id="VerticalLgtmIcon__Lgtm-sc-19v9h1n-0"]{content:"pFoNU,"}
.fsja-Dh > .banReason{list-style:disc;list-style-position:inside;margin:10px 0 10px;}
.fsja-Dh > .banReason > li{padding-left:12px;font-weight:bold;}
.fsja-Dh > .banReasonBody{font-size:15px;margin-bottom:10px;}
data-styled.g45[id="ArticleAlert-sc-14a2ewm-0"]{content:"fsja-Dh,"}
.ZHnTl{display:inline-block;width:56px;height:12.747967479674797px;fill:#55C500;}
data-styled.g46[id="LgtmIcon__Lgtm-sc-1e4ee48-0"]{content:"ZHnTl,"}
.fEysOa{display:inline-block;vertical-align:bottom;height:17.77777777777778px;width:16px;fill:#5D707C;}
data-styled.g47[id="StockIcon__Stock-cq5opj-0"]{content:"fEysOa,"}
</style><script>window.frtn=window.frtn||function(){ (frtn.q=frtn.q||[]).push(arguments) };
frtn("init",{
service_id:"cova_248",
site_id:"site_134",
tag_id:"tag_283"
});
frtn("send","pageview");</script><script defer="" src="https://frtn.socdm.com/tags/insight.js" type="text/javascript"></script><script>!function(t,e){if(void 0===e[t]){e[t]=function(){e[t].clients.push(this),this._init=[Array.prototype.slice.call(arguments)]},e[t].clients=[];for(var r=function(t){return function(){return this["_"+t]=this["_"+t]||[],this["_"+t].push(Array.prototype.slice.call(arguments)),this}},s=["blockEvents","unblockEvents","setSignedMode","setAnonymousMode","resetUUID","addRecord","fetchGlobalID","set","trackEvent","trackPageview","trackClicks","ready"],n=0;n<s.length;n++){var c=s[n];e[t].prototype[c]=r(c)}var o=document.createElement("script");o.type="text/javascript",o.async=!0,o.src=("https:"===document.location.protocol?"https:":"http:")+"//cdn.treasuredata.com/sdk/2.1/td.min.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(o,a)}}("Treasure",this);

// Configure an instance for your database
var td = new Treasure({
  host: 'in.treasuredata.com',
  writeKey: '10614/e3887673c1849754466b09ad01b4fbbc22b88f30',
  database: 'qiita_public',
  startInSignedMode: true
});

// Enable cross-domain tracking
td.set('$global', 'td_global_id', 'td_global_id');
// Track pageview information to 'pageviews' table
td.set('pageviews_all', {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"0NE_shoT_","type":"items","id":"08376b08783cd554b02e"},"user_id":null})
td.trackPageview('pageviews_all');</script></head><body><div class="allWrapper"><div class="st-HeaderContainer"><div id="GlobalHeader-react-component-d49ffb40-9bea-4c93-b016-a56c47420200"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div><div class="st-Header_realmSelector" tabindex="0"><span class="fa fa-fw fa-caret-down"></span></div><div class="st-Header_dropdown st-RealmSelector"><div class="st-RealmSelector_realms"><a class="st-Header_dropdownItem st-RealmItem" href="https://qiita.com/"><div class="st-RealmItem_statusIcon"><span class="fa fa-fw fa-check"></span></div><div class="st-RealmItem_humanName">Qiita</div></a></div><hr/><div class="st-RealmSelector_supplements"><div class="st-RealmSelector_label">ログイン中のチームがありません</div><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem st-RealmSelectorSupplement"><div class="st-RealmSelectorSupplement_icon"><span class="fa fa-fw fa-sign-in"></span></div><div>Qiita Team にログイン...</div></a></div></div></div><div><div class="st-Header_community" tabindex="0">コミュニティ<span class="fa fa-fw fa-caret-down ml-1of2"></span></div><div class="st-Header_dropdown"><a href="/users" class="st-Header_dropdownItem"><span class="fa fa-fw fa-users mr-1of2"></span>ユーザー一覧</a><a href="/organizations" class="st-Header_dropdownItem"><span class="fa fa-fw fa-building-o mr-1of2"></span>Organization一覧</a><a href="/advent-calendar" class="st-Header_dropdownItem"><span class="fa fa-fw fa-calendar mr-1of2"></span>アドベントカレンダー</a><div class="st-Header_dropdownSeparator"></div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-search mr-1of2"></span>Qiita Jobs</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-comments-o mr-1of2"></span>Qiitadon (β)</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-newspaper-o mr-1of2"></span>Qiita Zine</a><div class="st-Header_dropdownSeparator"></div><a href="https://help.qiita.com/ja/articles/qiita-community-guideline" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>コミュニティガイドライン</a><a href="https://help.qiita.com/ja/articles/qiita-article-guideline" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>良い記事を書くために</a><a href="/release-notes" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>リリースノート</a></div></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="キーワードを入力" value="" name="q" required=""/></form><div class="st-Header_searchButton"><span class="fa fa-search"></span></div></div><div class="st-Header_end"><a class="st-Header_signupButton" href="/signup?redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e">ユーザ登録</a><a class="st-Header_loginLink" href="/login?redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e">ログイン</a></div><div class="st-Header_overlay"></div><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="キーワードを入力" value="" name="q" required=""/></form></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-d49ffb40-9bea-4c93-b016-a56c47420200">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/%23%3CQiita::Graph::Result:0x00000000096fdfc0%3E","name":"Python"}}]}</script><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","datePublished":"2018-06-11T23:40:10.000+09:00","dateModified":"2019-12-30T17:14:55.000+09:00","headline":"Scikit-learn で線形回帰","image":"https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-1.2.2\u0026w=1200\u0026mark=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D380%26txt%3DScikit-learn%2520%25E3%2581%25A7%25E7%25B7%259A%25E5%25BD%25A2%25E5%259B%259E%25E5%25B8%25B0%26txt-color%3D%2523333%26txt-font%3DHiragino%2520Sans%2520W6%26txt-size%3D54%26txt-clip%3Dellipsis%26txt-align%3Dcenter%252Cmiddle%26s%3D9de9ec2f33b8b6dc73d1d09231d23753\u0026mark-align=center%2Cmiddle\u0026blend=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D500%26txt%3D%25400NE_shoT_%26txt-color%3D%2523333%26txt-font%3DHiragino%2520Sans%2520W6%26txt-size%3D45%26txt-align%3Dright%252Cbottom%26s%3D812515090497353474e8a1c5ba33624d\u0026blend-align=center%2Cmiddle\u0026blend-mode=normal\u0026s=748fd9192e28c33230ed6f66c4b073a2","mainEntityOfPage":"https://qiita.com/0NE_shoT_/items/08376b08783cd554b02e","author":{"@type":"Person","address":"Tokyo, Japan","email":null,"identifier":"0NE_shoT_","name":"0NE_shoT_","image":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fprofile-images%2F1526819848?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=8a125ec542a6b3dab2acaa64cee53a51","url":"https://qiita.com/0NE_shoT_","description":"新人データ分析コンサルタントとして働いています。最近はWebマーケティングの意思決定の判断材料となるデータ分析をしています。","memberOf":[]},"publisher":{"@type":"Organization","name":"Qiita","logo":{"@type":"ImageObject","url":"//cdn.qiita.com/assets/public/qiita-logo-green-36e6153054916b1d8ed7fc47163039da.png"}}}</script><script>td.trackEvent('pageviews_article',{
    user_id: "",
    article_id: "656715",
    article_uuid: "08376b08783cd554b02e",
    td_description: "&quot;# はじめに\n売り上げなどの数量（連続値をとる目的変数）を予測するのに役立つのが回帰です。この記事では、特に目的変数と説明変数の関係をモデル化する一つの方法である線形回帰をScikit-learnライブラリを使って行う方法について、備忘録として書いておきます。\n\n# Scikit-learn について\nScikit-learnは、Pythonの機械学習ライブラリの一つです。\n\n - 公式ドキュメント：http://scikit-learn.org/stable/index.html\n\n# 線形回帰について\n線形回帰は、連続値をとる目的変数 $y$ と説明変数 $x$（特徴量）の線形関係をモデル化します。線形関係とは、平たく言うと、説明変数が増加（減少）するのに応じて、目的変数も単調に増加（減少）する関係です。説明変数が一つの場合（単回帰と呼ぶ）、目的変数と説明変数の関係をモデル化する線形モデルは以下の式で定義されます。\n\n```math\ny = w_0 + w_1x\n```\n\nここで、重み $w_0$ は切片、重み $w_1$ は説明変数の係数を表します。線形回帰の目的は、説明変数と目的変数の関係を表現する線形モデルの重みを学習することです。上の式のように、目的変数が説明変数の一次式で表現されるとき、線形回帰は「説明変数と目的変数の散布図において、データの分布を最もよく特徴づける直線を探し出すこと」といえます。\n\n説明変数が複数の場合（重回帰と呼ぶ）、目的変数を説明変数の線形和で表現する線形モデルは以下の式で定義されます。\n\n\n```math\ny = w_0x_0 + w_1x_1 + \\cdots +w_mx_m = \\sum^m_{i=0}w_ix_i\n```\n\nここで、重み $w_0$ は $x_0=1$ として切片を表します。重回帰は、単回帰を複数の説明変数を扱扱えるように一般化したものであり、目的変数と複数の説明変数の関係を表すモデルの重みを学習することが目的です。\n\n# 線形回帰モデル\nscikit-learnで線形回帰をするには、linear_modelのLinearRegressionモデル（公式ドキュメント：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html ）を使います。主に利用するメソッドは以下の通りです。\n\n - fitメソッド：線形モデルの重みを学習\n - predictメソッド：線形モデルから目的変数を予測\n - scoreメソッド：決定係数（線形モデルがどの程度目的変数を説明できるか）を出力\n\n\nここでは、UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/index.php) で公開されている、ボストン市郊外の地域別住宅価格（https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ ）を使います。以下のコードでは、scikit-learnライブラリに付属のデータセットを読み込み、PandasのDataFrameに変換しています。（以降のコードの動作環境は、Python 3.7.3, pandas 0.24.2, scikit-learn 0.20.3 です。）\n\n```python\nfrom sklearn.datasets import load_boston\nboston = load_boston() # データセットの読み込み\n\nimport pandas as pd\nboston_df = pd.DataFrame(boston.data, columns = boston.feature_names) # 説明変数(boston.data)をDataFrameに保存\nboston_df[\u0026amp;#39;MEDV\u0026amp;#39;] = boston.target # 目的変数(boston.target)もDataFrameに追加\n```\nデータを覗いてみると、こんな感じです。\n\n```python\nboston_df.head()\n```\n\n\u0026amp;lt;img width=\u0026amp;quot;514\u0026amp;quot; alt=\u0026amp;quot;boston.jpg\u0026amp;quot; src=\u0026amp;quot;https://qiita-image-store.s3.amazonaws.com/0/258694/7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg\u0026amp;quot;\u0026amp;gt;\n\n各変数（データ項目）の説明は以下の通りです。\n\n| 変数    | 説明                                 |\n|:--------|:------------------------------------|\n| CRIM    | 犯罪発生率                           |\n| ZN      | 25,000平方フィート以上の住宅区画の割合 |\n| INDUS   | 非小売業種の土地面積の割合            |\n| CHAS    | チャールズ川沿いかを表すダミー変数     |\n| NOX     | 窒素酸化物の濃度                     |\n| RM      | 平均部屋数                           | \n| AGE     | 1940年より前に建てられた建物の割合     |\n| DIS     | 5つのボストンの雇用施設への重み付き距離 |\n| RAD     | 高速道路へのアクセスのしやすさ         |\n| TAX     | 10,000ドルあたりの不動産税率          |\n| PTRATIO | 生徒と教師の割合                     |\n| B       | 黒人の割合                          |\n| LSTAT   | 低所得者の割合                       |\n| MEDV    | 住宅価格の中央値（1,000単位）         |\n\nここで、例えば以下のコードを使ってRM（平均部屋数）とMEDV（住宅価格）の関係を見てみると、おおむね線形関係にある、つまり平均部屋数が多いほど住宅価格も高いように見えます。\n\n```python\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.scatter(boston_df[\u0026amp;#39;RM\u0026amp;#39;], boston_df[\u0026amp;#39;MEDV\u0026amp;#39;]) # 平均部屋数と住宅価格の散布図をプロット\n\nplt.title(\u0026amp;#39;Scatter Plot of RM vs MEDV\u0026amp;#39;)    # 図のタイトル\nplt.xlabel(\u0026amp;#39;Average number of rooms [RM]\u0026amp;#39;) # x軸のラベル\nplt.ylabel(\u0026amp;#39;Prices in $1000\\\u0026amp;#39;s [MEDV]\u0026amp;#39;)    # y軸のラベル\nplt.grid()                                 # グリッド線を表示\n\nplt.show()                                 # 図の表示\n```\n\n![scatter_plot2.jpg](https://qiita-image-store.s3.amazonaws.com/0/258694/6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg)\n\nPandasのcorr()メソッドで平均部屋数と住宅価格の相関係数を算出してみると、約0.7程度と正の相関があることがわかります。\n\n```python\nboston_df[[\u0026amp;#39;RM\u0026amp;#39;,\u0026amp;#39;MEDV\u0026amp;#39;]].corr()\n```\n\n\u0026amp;lt;img width=\u0026amp;quot;124\u0026amp;quot; alt=\u0026amp;quot;corr.jpg\u0026amp;quot; src=\u0026amp;quot;https://qiita-image-store.s3.amazonaws.com/0/258694/8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg\u0026amp;quot;\u0026amp;gt;\n\n以降では、住宅価格（目的変数）と平均部屋数（説明変数）の関係を表現する線形回帰モデルを構築してみます。\n# 線形回帰モデルの構築\nfitメソッドで重みを学習することで、線形回帰モデルを構築します。学習の際には、説明変数Xと目的変数YにはNumpyの配列を利用するため、values属性で説明変数と目的変数の列からNumpyの配列を取り出しています。\n\n```python\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\nX = boston_df[[\u0026amp;#39;RM\u0026amp;#39;]].values         # 説明変数（Numpyの配列）\nY = boston_df[\u0026amp;#39;MEDV\u0026amp;#39;].values         # 目的変数（Numpyの配列）\n\nlr.fit(X, Y)                         # 線形モデルの重みを学習\n```\n学習により得られた、線形モデルの切片 $w_0$ はintercept_属性に、説明変数の係数 $w_1$ はcoef_属性に格納されます。学習結果を確認すると、係数は約9.1、切片は約-34.7であることがわかります。\n\n```python\nprint(\u0026amp;#39;coefficient = \u0026amp;#39;, lr.coef_[0]) # 説明変数の係数を出力\nprint(\u0026amp;#39;intercept = \u0026amp;#39;, lr.intercept_) # 切片を出力\n\ncoefficient =  9.10210898118\nintercept =  -34.6706207764\n```\n学習で得られた切片と係数を利用して、回帰直線を引いてみます。回帰直線をプロットするには、線形モデルに説明変数の値を与えたときの目的変数の値（予測値）が必要になります。以下のコードでは、これを得るためにpredictメソッドを利用しています。\n\n```python\nplt.scatter(X, Y, color = \u0026amp;#39;blue\u0026amp;#39;)         # 説明変数と目的変数のデータ点の散布図をプロット\nplt.plot(X, lr.predict(X), color = \u0026amp;#39;red\u0026amp;#39;) # 回帰直線をプロット\n\nplt.title(\u0026amp;#39;Regression Line\u0026amp;#39;)               # 図のタイトル\nplt.xlabel(\u0026amp;#39;Average number of rooms [RM]\u0026amp;#39;) # x軸のラベル\nplt.ylabel(\u0026amp;#39;Prices in $1000\\\u0026amp;#39;s [MEDV]\u0026amp;#39;)    # y軸のラベル\nplt.grid()                                 # グリッド線を表示\n\nplt.show()                                 # 図の表示\n```\n与えられたデータ点にある程度フィットした回帰直線を引くことができていることが確認できます。\n\n![regression_line.jpg](https://qiita-image-store.s3.amazonaws.com/0/258694/8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg)\n\n# 線形回帰モデルの性能評価\n学習により得られた線形モデルの性能を評価するには、学習には用いていないデータでモデルを検証することが必要です。構築したモデルを今後利用する（例：売上予測モデルの予測結果を使ってビジネス計画を策定する・なんらかの施策を打っていく）ことを考慮すると、モデル構築時には得られない将来のデータに対して精度よく予測できることが重要であるためです。そのためには、まず手元のデータを学習データと検証データに分けます。そして、学習データでモデルを構築し、検証データを将来のデータと見立て、これに対するモデルの性能（汎化性能と呼ぶ）を評価します。\n\n以下のコードでは、model_selectionのtrain_test_split（公式ドキュメント：http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html ）を利用して、データを学習用と検証用に7:3の割合で分割し、学習データを用いて線形モデルを構築しています。\n\n```python\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.7, test_size = 0.3, random_state = 0) # データを学習用と検証用に分割\n\nlr = LinearRegression()\nlr.fit(X_train, Y_train) # 線形モデルの重みを学習\n```\n線形回帰モデルの性能評価には、主に以下の方法・指標を利用します。\n\n - 残差プロット：残差（目的変数の真値と予測値の差分）を可視化\n - 平均二乗誤差：残差平方和をデータ数で正規化した値\n - 決定係数：相関係数の二乗\n\n残差プロットは、残差（目的変数の真値と予測値の差分）の分布を可視化したものです。線形モデルが目的変数を完璧に予測できる場合は残差は0となるので、予測精度の良い線形モデルの残差プロットは、0を中心にランダムにばらついたものになります。残差プロットに何かパターンが見られる場合は、線形モデルで説明しきれない情報があることが示唆されます。以下のコードは、残差プロットを描画します。\n\n```python\n\nY_pred = lr.predict(X_test) # 検証データを用いて目的変数を予測\n\nplt.scatter(Y_pred, Y_pred - Y_test, color = \u0026amp;#39;blue\u0026amp;#39;)      # 残差をプロット \nplt.hlines(y = 0, xmin = -10, xmax = 50, color = \u0026amp;#39;black\u0026amp;#39;) # x軸に沿った直線をプロット\nplt.title(\u0026amp;#39;Residual Plot\u0026amp;#39;)                                # 図のタイトル\nplt.xlabel(\u0026amp;#39;Predicted Values\u0026amp;#39;)                            # x軸のラベル\nplt.ylabel(\u0026amp;#39;Residuals\u0026amp;#39;)                                   # y軸のラベル\nplt.grid()                                                # グリッド線を表示\n\nplt.show()                                               # 図の表示\n```\n残差プロットを見てみると、残差は0を中心に分布していますが、線形モデルで説明しきれないパターンもあるように見えます。\n\n![residual_plot.jpg](https://qiita-image-store.s3.amazonaws.com/0/258694/ce893435-4080-ac48-abe7-baef1a3bd010.jpeg)\n\n平均二乗誤差は、残差の平方和をデータ数で正規化したものであり、モデルの性能を数値化するのに役立ちます。もちろん、誤差が小さいほどモデルの性能は良いといえます。平均二乗誤差は、metricsのmean_squared_errorを利用することで算出できます。\n\n```python\nfrom sklearn.metrics import mean_squared_error\n\nY_train_pred = lr.predict(X_train) # 学習データに対する目的変数を予測\nprint(\u0026amp;#39;MSE train data: \u0026amp;#39;, mean_squared_error(Y_train, Y_train_pred)) # 学習データを用いたときの平均二乗誤差を出力\nprint(\u0026amp;#39;MSE test data: \u0026amp;#39;, mean_squared_error(Y_test, Y_pred))         # 検証データを用いたときの平均二乗誤差を出力\n```\n学習データ、検証データそれぞれを用いたときの平均二乗誤差を比較すると、検証データを用いたときの誤差の方が大きいことがわかります。このことから、構築した線形モデルは学習データにフィットしすぎている（過学習と呼ぶ）ことが示唆されます。\n\n```python\nMSE train data:  42.1576508631\nMSE test data:  47.0330474798\n```\n決定係数も、線形モデルの予測誤差を反映した指標であり、値が大きいほど線形モデルがデータにフィットしているといえます。決定係数は、metricsのr2_scoreを利用することで算出できます。また、LinearRegressionモデルのscoreメソッドでも算出できます。\n\n```python\nfrom sklearn.metrics import r2_score\n\nprint(\u0026amp;#39;r^2 train data: \u0026amp;#39;, r2_score(Y_train, Y_train_pred))\nprint(\u0026amp;#39;r^2 test data: \u0026amp;#39;, r2_score(Y_test, Y_pred))\n```\n学習データ、検証データそれぞれを用いたときの決定係数を比較すると、検証データを用いたときの決定係数の方が小さいことがわかります。このことからも、構築した線形モデルには過学習が起こっている可能性があることがわかります。\n\n```Python\nr^2 train data:  0.502649763004\nr^2 test data:  0.435143648321\n```\n\nここまでは単回帰のコード例を示してきましたが、重回帰の場合も簡単に試すことができます。\n例えば、住宅価格（目的変数）と、平均部屋数および低所得者の割合（説明変数）の関係を表現する線形回帰モデルは、以下のようなコードで構築することができます。\n\n```python\nlr = LinearRegression()\n\nX = boston_df[[\u0026amp;#39;RM\u0026amp;#39;, \u0026amp;#39;LSTAT\u0026amp;#39;]].values         # 説明変数（Numpyの配列）\nY = boston_df[\u0026amp;#39;MEDV\u0026amp;#39;].values         # 目的変数（Numpyの配列）\n\nlr.fit(X, Y)                         # 線形モデルの重みを学習\n```\n\n\n# おわりに\nこの記事では、scikit-learnライブラリで線形回帰をする方法について簡単に触れました。目的変数をより精度よく表現する線形モデルを構築するためには、特徴量（説明変数）選択や正則化を行うことを検討する必要がありますが、その点についても今後まとめてみようと思います。\n\n# 参考\n - [第2版]Python機械学習プログラミング 達人データサイエンティストによる理論と実装（https://www.amazon.co.jp/dp/B07BF5QZ41/ref=dp-kindle-redirect?_encoding=UTF8\u0026amp;amp;btkr=1 ）\n\n# 更新履歴\n- （2019/12/30）重回帰のコード例の追記\n&quot;",
    td_title: "&quot;Scikit-learn で線形回帰&quot;"
  })</script><style type="text/css">.wb-CampaignLink {
  background-color: #333333;
  width: 100%;
}

.wb-CampaignLink_container {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  max-width: 1100px;
  margin: 0 auto;
  font-size: 13px;
  padding: 0.8em;

}
.wb-CampaignLink_container > a {
  color: #fff;
}

.wb-CampaignLink_container > a:hover {
  text-decoration: underline;
}</style><style type="text/css">.wb-CampaignLink {
  background-color: #333333;
  width: 100%;
}

.wb-CampaignLink_container {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  max-width: 1100px;
  margin: 0 auto;
  font-size: 13px;
  padding: 0.8em;

}
.wb-CampaignLink_container > a {
  color: #fff;
}

.wb-CampaignLink_container > a:hover {
  text-decoration: underline;
}</style><div class="wb-CampaignLink"><div class="wb-CampaignLink_container"><a target="_blank" href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=header&amp;utm_campaign=jobseeker_202008&amp;utm_content=text8">Qiitaでの活動が評価されるQiita Jobsで転職しませんか？</a><a target="_blank" href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=header&amp;utm_campaign=jobseeker_202008&amp;utm_content=text8">詳しくはこちら</a></div></div><script async="" src="https://cdn.bigmining.com/private/js/qiita_bigmining.js"></script><div style="display:none"><div class="TagList__label"><span></span><span>Python</span></div><div class="TagList__label"><span></span><span>機械学習</span></div><div class="TagList__label"><span></span><span>scikit-learn</span></div></div><img style="display:block;margin:0;padding:0;border:0;outline:0;width:0;height:0;line-height:0;" alt="" src="https://relay-dsp.ad-m.asia/dmp/sync/bizmatrix?pid=c3ed207b574cf11376&amp;d=x18o8hduaj&amp;uid=" /><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"ja","i18nDefaultLocale":"en","href":"https://qiita.com/0NE_shoT_/items/08376b08783cd554b02e","location":"/0NE_shoT_/items/08376b08783cd554b02e","scheme":"https","host":"qiita.com","port":null,"pathname":"/0NE_shoT_/items/08376b08783cd554b02e","search":null,"httpAcceptLanguage":"ja,en-US;q=0.9,en;q=0.8","actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","assetsMap":{},"csrfToken":"+rRloMeIbu4rI2dt8ietYmZP+zEAo3MLIeGEVVpwSkpMN7CeaUZVskpdi+InyHG5rEIKoCXWyiESCFZgYzkREw==","locale":"ja"},"currentUser":null,"isLoggedIn":false,"recaptchaSiteKey":"6LfNkiQTAAAAAM3UGnSquBy2akTITGNMO_QDxMw6","serverSide":false}</script>
<div id="PersonalArticlePage-react-component-8dc18eb5-7cc1-49d0-a449-9a66b202c15b"><div class="p-items"><div class="p-items_wrapper"><div class="p-items_container"><div class="p-items_main"><div class="p-items_article"><div class="it-Header"><div class="u-flex-center-between mb-3"><div class="it-Header_info"><div class="it-Header_author"><a href="/0NE_shoT_"><img src="https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fprofile-images%2F1526819848?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;lossless=0&amp;w=48&amp;s=34cb790dd8c26a62da1ffb147b11d45a" alt="0NE_shoT_" class="it-Header_authorImage"/></a><a href="/0NE_shoT_" class="it-Header_authorName">@<!-- -->0NE_shoT_</a></div><div class="it-Header_time"><span title="2018年06月11日に投稿" class=""><meta content="2018-06-11T14:40:10Z"/><time dateTime="2019-12-30T08:14:55Z">2019年12月30日に更新</time></span></div><div class="it-Header_meta"><div class="it-Header_manipulate"><div class="it-Header_dropdown"><span class="it-Header_dropdownToggle" tabindex="0"><span class="fa fa-ellipsis-h fa-lg"></span></span><div class="st-Dropdown right"><div><div class="it-Header_dropdown-title">記事の改善</div><a class="st-Dropdown_item" href="/drafts/08376b08783cd554b02e/edit"><span class="fa fa-fw fa-code-fork pr-1"></span>編集リクエストを送る</a><div class="st-Dropdown_separator"></div></div><div class="it-Header_dropdown-title">記事の情報</div><a class="st-Dropdown_item" href="/0NE_shoT_/items/08376b08783cd554b02e/revisions"><span class="fa fa-fw fa-history pr-1"></span>編集履歴</a><a class="st-Dropdown_item" href="/0NE_shoT_/items/08376b08783cd554b02e/patches"><span class="fa fa-fw fa-inbox pr-1"></span>編集リクエスト一覧</a><a class="st-Dropdown_item" href="/0NE_shoT_/items/08376b08783cd554b02e/likers"><span style="margin-right:4px"><svg size="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#777" class="VerticalLgtmIcon__Lgtm-sc-19v9h1n-0 pFoNU"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>LGTMしたユーザ一覧</a><a class="st-Dropdown_item" href="/0NE_shoT_/items/08376b08783cd554b02e.md"><span class="fa fa-fw fa-file-text-o pr-1"></span>Markdown で本文を見る</a><div class="st-Dropdown_separator"></div><div class="st-Dropdown_item"><span class="fa fa-fw fa-flag pr-1"></span>問題がある記事を報告する</div></div></div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">この記事にどのような問題がありますか？</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>法律違反（著作権侵害、プライバシー侵害、名誉棄損等）</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>社会的に不適切（公序良俗に反する）</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>宣伝行為</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>スパムの疑い</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>上記以外だが、Qiitaのコミュニティにふさわしくない（ガイドライン違反）</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="送信"/></div></form></div></div></div></div></div><h1 class="it-Header_title">Scikit-learn で線形回帰</h1><div class="it-Tags"><a href="/tags/python" class="it-Tags_item"><span>Python</span></a><a href="/tags/%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92" class="it-Tags_item"><span>機械学習</span></a><a href="/tags/scikit-learn" class="it-Tags_item"><span>scikit-learn</span></a></div></div><section class="it-MdContent"><div id="personal-public-article-body"><div>
<h1>
<span id="はじめに" class="fragment"></span><a href="#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB"><i class="fa fa-link"></i></a>はじめに</h1>

<p>売り上げなどの数量（連続値をとる目的変数）を予測するのに役立つのが回帰です。この記事では、特に目的変数と説明変数の関係をモデル化する一つの方法である線形回帰をScikit-learnライブラリを使って行う方法について、備忘録として書いておきます。</p>

<h1>
<span id="scikit-learn-について" class="fragment"></span><a href="#scikit-learn-%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><i class="fa fa-link"></i></a>Scikit-learn について</h1>

<p>Scikit-learnは、Pythonの機械学習ライブラリの一つです。</p>

<ul>
<li>公式ドキュメント：<a href="http://scikit-learn.org/stable/index.html" class="autolink" rel="nofollow noopener" target="_blank">http://scikit-learn.org/stable/index.html</a>
</li>
</ul>

<h1>
<span id="線形回帰について" class="fragment"></span><a href="#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><i class="fa fa-link"></i></a>線形回帰について</h1>

<p>線形回帰は、連続値をとる目的変数 $y$ と説明変数 $x$（特徴量）の線形関係をモデル化します。線形関係とは、平たく言うと、説明変数が増加（減少）するのに応じて、目的変数も単調に増加（減少）する関係です。説明変数が一つの場合（単回帰と呼ぶ）、目的変数と説明変数の関係をモデル化する線形モデルは以下の式で定義されます。</p>

<div class="code-frame" data-lang="math"><div class="highlight"><pre>y = w_0 + w_1x
</pre></div></div>

<p>ここで、重み $w_0$ は切片、重み $w_1$ は説明変数の係数を表します。線形回帰の目的は、説明変数と目的変数の関係を表現する線形モデルの重みを学習することです。上の式のように、目的変数が説明変数の一次式で表現されるとき、線形回帰は「説明変数と目的変数の散布図において、データの分布を最もよく特徴づける直線を探し出すこと」といえます。</p>

<p>説明変数が複数の場合（重回帰と呼ぶ）、目的変数を説明変数の線形和で表現する線形モデルは以下の式で定義されます。</p>

<div class="code-frame" data-lang="math"><div class="highlight"><pre>y = w_0x_0 + w_1x_1 + \cdots +w_mx_m = \sum^m_{i=0}w_ix_i
</pre></div></div>

<p>ここで、重み $w_0$ は $x_0=1$ として切片を表します。重回帰は、単回帰を複数の説明変数を扱扱えるように一般化したものであり、目的変数と複数の説明変数の関係を表すモデルの重みを学習することが目的です。</p>

<h1>
<span id="線形回帰モデル" class="fragment"></span><a href="#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB"><i class="fa fa-link"></i></a>線形回帰モデル</h1>

<p>scikit-learnで線形回帰をするには、linear_modelのLinearRegressionモデル（公式ドキュメント：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" class="autolink" rel="nofollow noopener" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a> ）を使います。主に利用するメソッドは以下の通りです。</p>

<ul>
<li>fitメソッド：線形モデルの重みを学習</li>
<li>predictメソッド：線形モデルから目的変数を予測</li>
<li>scoreメソッド：決定係数（線形モデルがどの程度目的変数を説明できるか）を出力</li>
</ul>

<p>ここでは、UCI Machine Learning Repository (<a href="http://archive.ics.uci.edu/ml/index.php" class="autolink" rel="nofollow noopener" target="_blank">http://archive.ics.uci.edu/ml/index.php</a>) で公開されている、ボストン市郊外の地域別住宅価格（<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/" class="autolink" rel="nofollow noopener" target="_blank">https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</a> ）を使います。以下のコードでは、scikit-learnライブラリに付属のデータセットを読み込み、PandasのDataFrameに変換しています。（以降のコードの動作環境は、Python 3.7.3, pandas 0.24.2, scikit-learn 0.20.3 です。）</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span> <span class="c1"># データセットの読み込み
</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">boston_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">boston</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">boston</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span> <span class="c1"># 説明変数(boston.data)をDataFrameに保存
</span><span class="n">boston_df</span><span class="p">[</span><span class="s">'MEDV'</span><span class="p">]</span> <span class="o">=</span> <span class="n">boston</span><span class="p">.</span><span class="n">target</span> <span class="c1"># 目的変数(boston.target)もDataFrameに追加
</span></pre></div></div>

<p>データを覗いてみると、こんな感じです。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="n">boston_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></div></div>

<p><a href="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=1d4e7b75cc95ebf4d871724e01beff26" target="_blank" rel="nofollow noopener"><img width="514" alt="boston.jpg" src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=1d4e7b75cc95ebf4d871724e01beff26" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/258694/7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=76062d3516a0e2c412eb1ff7e548e3d2 1x" loading="lazy"></a></p>

<p>各変数（データ項目）の説明は以下の通りです。</p>

<table>
<thead>
<tr>
<th style="text-align: left">変数</th>
<th style="text-align: left">説明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left">CRIM</td>
<td style="text-align: left">犯罪発生率</td>
</tr>
<tr>
<td style="text-align: left">ZN</td>
<td style="text-align: left">25,000平方フィート以上の住宅区画の割合</td>
</tr>
<tr>
<td style="text-align: left">INDUS</td>
<td style="text-align: left">非小売業種の土地面積の割合</td>
</tr>
<tr>
<td style="text-align: left">CHAS</td>
<td style="text-align: left">チャールズ川沿いかを表すダミー変数</td>
</tr>
<tr>
<td style="text-align: left">NOX</td>
<td style="text-align: left">窒素酸化物の濃度</td>
</tr>
<tr>
<td style="text-align: left">RM</td>
<td style="text-align: left">平均部屋数</td>
</tr>
<tr>
<td style="text-align: left">AGE</td>
<td style="text-align: left">1940年より前に建てられた建物の割合</td>
</tr>
<tr>
<td style="text-align: left">DIS</td>
<td style="text-align: left">5つのボストンの雇用施設への重み付き距離</td>
</tr>
<tr>
<td style="text-align: left">RAD</td>
<td style="text-align: left">高速道路へのアクセスのしやすさ</td>
</tr>
<tr>
<td style="text-align: left">TAX</td>
<td style="text-align: left">10,000ドルあたりの不動産税率</td>
</tr>
<tr>
<td style="text-align: left">PTRATIO</td>
<td style="text-align: left">生徒と教師の割合</td>
</tr>
<tr>
<td style="text-align: left">B</td>
<td style="text-align: left">黒人の割合</td>
</tr>
<tr>
<td style="text-align: left">LSTAT</td>
<td style="text-align: left">低所得者の割合</td>
</tr>
<tr>
<td style="text-align: left">MEDV</td>
<td style="text-align: left">住宅価格の中央値（1,000単位）</td>
</tr>
</tbody>
</table>

<p>ここで、例えば以下のコードを使ってRM（平均部屋数）とMEDV（住宅価格）の関係を見てみると、おおむね線形関係にある、つまり平均部屋数が多いほど住宅価格も高いように見えます。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">boston_df</span><span class="p">[</span><span class="s">'RM'</span><span class="p">],</span> <span class="n">boston_df</span><span class="p">[</span><span class="s">'MEDV'</span><span class="p">])</span> <span class="c1"># 平均部屋数と住宅価格の散布図をプロット
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Scatter Plot of RM vs MEDV'</span><span class="p">)</span>    <span class="c1"># 図のタイトル
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Average number of rooms [RM]'</span><span class="p">)</span> <span class="c1"># x軸のラベル
</span><span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Prices in $1000</span><span class="si">\</span><span class="se">'</span><span class="s">s [MEDV]'</span><span class="p">)</span>    <span class="c1"># y軸のラベル
</span><span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>                                 <span class="c1"># グリッド線を表示
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>                                 <span class="c1"># 図の表示
</span></pre></div></div>

<p><a href="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=c097a18be2bc1723e49bf5d814e36043" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=c097a18be2bc1723e49bf5d814e36043" alt="scatter_plot2.jpg" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/258694/6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=8c5775ad961b380240a925063394380c 1x" loading="lazy"></a></p>

<p>Pandasのcorr()メソッドで平均部屋数と住宅価格の相関係数を算出してみると、約0.7程度と正の相関があることがわかります。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="n">boston_df</span><span class="p">[[</span><span class="s">'RM'</span><span class="p">,</span><span class="s">'MEDV'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</pre></div></div>

<p><a href="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=680bdd7355a9c7fd8f29c16ebe520989" target="_blank" rel="nofollow noopener"><img width="124" alt="corr.jpg" src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=680bdd7355a9c7fd8f29c16ebe520989" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/258694/8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=64d4d4059ff78cc26167418aae52cf9d 1x" loading="lazy"></a></p>

<p>以降では、住宅価格（目的変数）と平均部屋数（説明変数）の関係を表現する線形回帰モデルを構築してみます。</p>

<h1>
<span id="線形回帰モデルの構築" class="fragment"></span><a href="#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89"><i class="fa fa-link"></i></a>線形回帰モデルの構築</h1>

<p>fitメソッドで重みを学習することで、線形回帰モデルを構築します。学習の際には、説明変数Xと目的変数YにはNumpyの配列を利用するため、values属性で説明変数と目的変数の列からNumpyの配列を取り出しています。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">boston_df</span><span class="p">[[</span><span class="s">'RM'</span><span class="p">]].</span><span class="n">values</span>         <span class="c1"># 説明変数（Numpyの配列）
</span><span class="n">Y</span> <span class="o">=</span> <span class="n">boston_df</span><span class="p">[</span><span class="s">'MEDV'</span><span class="p">].</span><span class="n">values</span>         <span class="c1"># 目的変数（Numpyの配列）
</span>
<span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>                         <span class="c1"># 線形モデルの重みを学習
</span></pre></div></div>

<p>学習により得られた、線形モデルの切片 $w_0$ はintercept_属性に、説明変数の係数 $w_1$ はcoef_属性に格納されます。学習結果を確認すると、係数は約9.1、切片は約-34.7であることがわかります。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="s">'coefficient = '</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 説明変数の係数を出力
</span><span class="k">print</span><span class="p">(</span><span class="s">'intercept = '</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span> <span class="c1"># 切片を出力
</span>
<span class="n">coefficient</span> <span class="o">=</span>  <span class="mf">9.10210898118</span>
<span class="n">intercept</span> <span class="o">=</span>  <span class="o">-</span><span class="mf">34.6706207764</span>
</pre></div></div>

<p>学習で得られた切片と係数を利用して、回帰直線を引いてみます。回帰直線をプロットするには、線形モデルに説明変数の値を与えたときの目的変数の値（予測値）が必要になります。以下のコードでは、これを得るためにpredictメソッドを利用しています。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span><span class="p">)</span>         <span class="c1"># 説明変数と目的変数のデータ点の散布図をプロット
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'red'</span><span class="p">)</span> <span class="c1"># 回帰直線をプロット
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Regression Line'</span><span class="p">)</span>               <span class="c1"># 図のタイトル
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Average number of rooms [RM]'</span><span class="p">)</span> <span class="c1"># x軸のラベル
</span><span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Prices in $1000</span><span class="si">\</span><span class="se">'</span><span class="s">s [MEDV]'</span><span class="p">)</span>    <span class="c1"># y軸のラベル
</span><span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>                                 <span class="c1"># グリッド線を表示
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>                                 <span class="c1"># 図の表示
</span></pre></div></div>

<p>与えられたデータ点にある程度フィットした回帰直線を引くことができていることが確認できます。</p>

<p><a href="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=6280e94d1460ef7bdafe8021b262e078" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=6280e94d1460ef7bdafe8021b262e078" alt="regression_line.jpg" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/258694/8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=ea36559a71b2bde0ef6d0b2cb834da9d 1x" loading="lazy"></a></p>

<h1>
<span id="線形回帰モデルの性能評価" class="fragment"></span><a href="#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%80%A7%E8%83%BD%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>線形回帰モデルの性能評価</h1>

<p>学習により得られた線形モデルの性能を評価するには、学習には用いていないデータでモデルを検証することが必要です。構築したモデルを今後利用する（例：売上予測モデルの予測結果を使ってビジネス計画を策定する・なんらかの施策を打っていく）ことを考慮すると、モデル構築時には得られない将来のデータに対して精度よく予測できることが重要であるためです。そのためには、まず手元のデータを学習データと検証データに分けます。そして、学習データでモデルを構築し、検証データを将来のデータと見立て、これに対するモデルの性能（汎化性能と呼ぶ）を評価します。</p>

<p>以下のコードでは、model_selectionのtrain_test_split（公式ドキュメント：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" class="autolink" rel="nofollow noopener" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html</a> ）を利用して、データを学習用と検証用に7:3の割合で分割し、学習データを用いて線形モデルを構築しています。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># データを学習用と検証用に分割
</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span> <span class="c1"># 線形モデルの重みを学習
</span></pre></div></div>

<p>線形回帰モデルの性能評価には、主に以下の方法・指標を利用します。</p>

<ul>
<li>残差プロット：残差（目的変数の真値と予測値の差分）を可視化</li>
<li>平均二乗誤差：残差平方和をデータ数で正規化した値</li>
<li>決定係数：相関係数の二乗</li>
</ul>

<p>残差プロットは、残差（目的変数の真値と予測値の差分）の分布を可視化したものです。線形モデルが目的変数を完璧に予測できる場合は残差は0となるので、予測精度の良い線形モデルの残差プロットは、0を中心にランダムにばらついたものになります。残差プロットに何かパターンが見られる場合は、線形モデルで説明しきれない情報があることが示唆されます。以下のコードは、残差プロットを描画します。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># 検証データを用いて目的変数を予測
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">,</span> <span class="n">Y_pred</span> <span class="o">-</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span><span class="p">)</span>      <span class="c1"># 残差をプロット 
</span><span class="n">plt</span><span class="p">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">xmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span> <span class="c1"># x軸に沿った直線をプロット
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Residual Plot'</span><span class="p">)</span>                                <span class="c1"># 図のタイトル
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predicted Values'</span><span class="p">)</span>                            <span class="c1"># x軸のラベル
</span><span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Residuals'</span><span class="p">)</span>                                   <span class="c1"># y軸のラベル
</span><span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>                                                <span class="c1"># グリッド線を表示
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>                                               <span class="c1"># 図の表示
</span></pre></div></div>

<p>残差プロットを見てみると、残差は0を中心に分布していますが、線形モデルで説明しきれないパターンもあるように見えます。</p>

<p><a href="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fce893435-4080-ac48-abe7-baef1a3bd010.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=05e4f7d40b758432b3c8bdce62ec822a" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fce893435-4080-ac48-abe7-baef1a3bd010.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=05e4f7d40b758432b3c8bdce62ec822a" alt="residual_plot.jpg" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/258694/ce893435-4080-ac48-abe7-baef1a3bd010.jpeg" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fce893435-4080-ac48-abe7-baef1a3bd010.jpeg?ixlib=rb-1.2.2&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=55c6e55396fb51754dff2fa2eede8474 1x" loading="lazy"></a></p>

<p>平均二乗誤差は、残差の平方和をデータ数で正規化したものであり、モデルの性能を数値化するのに役立ちます。もちろん、誤差が小さいほどモデルの性能は良いといえます。平均二乗誤差は、metricsのmean_squared_errorを利用することで算出できます。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="n">Y_train_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="c1"># 学習データに対する目的変数を予測
</span><span class="k">print</span><span class="p">(</span><span class="s">'MSE train data: '</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_train_pred</span><span class="p">))</span> <span class="c1"># 学習データを用いたときの平均二乗誤差を出力
</span><span class="k">print</span><span class="p">(</span><span class="s">'MSE test data: '</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>         <span class="c1"># 検証データを用いたときの平均二乗誤差を出力
</span></pre></div></div>

<p>学習データ、検証データそれぞれを用いたときの平均二乗誤差を比較すると、検証データを用いたときの誤差の方が大きいことがわかります。このことから、構築した線形モデルは学習データにフィットしすぎている（過学習と呼ぶ）ことが示唆されます。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="n">MSE</span> <span class="n">train</span> <span class="n">data</span><span class="p">:</span>  <span class="mf">42.1576508631</span>
<span class="n">MSE</span> <span class="n">test</span> <span class="n">data</span><span class="p">:</span>  <span class="mf">47.0330474798</span>
</pre></div></div>

<p>決定係数も、線形モデルの予測誤差を反映した指標であり、値が大きいほど線形モデルがデータにフィットしているといえます。決定係数は、metricsのr2_scoreを利用することで算出できます。また、LinearRegressionモデルのscoreメソッドでも算出できます。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="k">print</span><span class="p">(</span><span class="s">'r^2 train data: '</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_train_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'r^2 test data: '</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>
</pre></div></div>

<p>学習データ、検証データそれぞれを用いたときの決定係数を比較すると、検証データを用いたときの決定係数の方が小さいことがわかります。このことからも、構築した線形モデルには過学習が起こっている可能性があることがわかります。</p>

<div class="code-frame" data-lang="Python"><div class="highlight"><pre><span class="n">r</span><span class="o">^</span><span class="mi">2</span> <span class="n">train</span> <span class="n">data</span><span class="p">:</span>  <span class="mf">0.502649763004</span>
<span class="n">r</span><span class="o">^</span><span class="mi">2</span> <span class="n">test</span> <span class="n">data</span><span class="p">:</span>  <span class="mf">0.435143648321</span>
</pre></div></div>

<p>ここまでは単回帰のコード例を示してきましたが、重回帰の場合も簡単に試すことができます。<br>
例えば、住宅価格（目的変数）と、平均部屋数および低所得者の割合（説明変数）の関係を表現する線形回帰モデルは、以下のようなコードで構築することができます。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre><span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">boston_df</span><span class="p">[[</span><span class="s">'RM'</span><span class="p">,</span> <span class="s">'LSTAT'</span><span class="p">]].</span><span class="n">values</span>         <span class="c1"># 説明変数（Numpyの配列）
</span><span class="n">Y</span> <span class="o">=</span> <span class="n">boston_df</span><span class="p">[</span><span class="s">'MEDV'</span><span class="p">].</span><span class="n">values</span>         <span class="c1"># 目的変数（Numpyの配列）
</span>
<span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>                         <span class="c1"># 線形モデルの重みを学習
</span></pre></div></div>

<h1>
<span id="おわりに" class="fragment"></span><a href="#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB"><i class="fa fa-link"></i></a>おわりに</h1>

<p>この記事では、scikit-learnライブラリで線形回帰をする方法について簡単に触れました。目的変数をより精度よく表現する線形モデルを構築するためには、特徴量（説明変数）選択や正則化を行うことを検討する必要がありますが、その点についても今後まとめてみようと思います。</p>

<h1>
<span id="参考" class="fragment"></span><a href="#%E5%8F%82%E8%80%83"><i class="fa fa-link"></i></a>参考</h1>

<ul>
<li>[第2版]Python機械学習プログラミング 達人データサイエンティストによる理論と実装（<a href="https://www.amazon.co.jp/dp/B07BF5QZ41/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1" class="autolink" rel="nofollow noopener" target="_blank">https://www.amazon.co.jp/dp/B07BF5QZ41/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1</a> ）</li>
</ul>

<h1>
<span id="更新履歴" class="fragment"></span><a href="#%E6%9B%B4%E6%96%B0%E5%B1%A5%E6%AD%B4"><i class="fa fa-link"></i></a>更新履歴</h1>

<ul>
<li>（2019/12/30）重回帰のコード例の追記</li>
</ul>
</div></div></section><div class="it-Footer"><div class="it-Footer_actions"><div class="it-Footer_editRequest"><a href="/drafts/08376b08783cd554b02e/edit" class="u-link-no-underline"><span>編集リクエスト</span></a></div><div class="it-Footer_stock"><button><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" class="StockIcon__Stock-cq5opj-0 fEysOa"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg><span class="it-Footer_stockLabel">ストック</span></button></div><div class="it-Footer_like" title="Looks Good To Me!"><button style="background-color:#fff"><span style="width:100%;height:100%;display:flex;align-items:center;justify-content:center"><svg size="56" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 564.81 145.68" color="#55C500" class="LgtmIcon__Lgtm-sc-1e4ee48-0 ZHnTl"><path d="M0 3.85h38.39v106.5h64.16v32H0zM195.41 66.82h71.82q.91 17.84-4 32.35A68.89 68.89 0 01248.71 124a65.49 65.49 0 01-22.9 16 74.08 74.08 0 01-29.17 5.65 78.16 78.16 0 01-54.17-21.32 74.1 74.1 0 01-16.42-23.21 68.08 68.08 0 01-6-28.41 67.7 67.7 0 016-28.42 74.44 74.44 0 0116.42-23.1 76.37 76.37 0 0124.32-15.52 78.92 78.92 0 0184.43 16.06l-25 25A36.52 36.52 0 00213.57 36a37.65 37.65 0 00-31.83-.87 37.7 37.7 0 00-12.08 8.57 40.75 40.75 0 00-8.17 12.91 42.8 42.8 0 00-3 16.22 42.91 42.91 0 003 16.17 40.44 40.44 0 008.17 13 37.4 37.4 0 0012.08 8.57 36.07 36.07 0 0014.9 3.11q14.38 0 22.13-5.35a25.46 25.46 0 0010.31-14.65h-33.77zM319.44 36.21h-36.55v-32h111.18v32h-36.45v106.5h-38.18zM486.82 109l-29.73-44.18v77.89H418.7V4.24h33.83l39 55.09 39.86-55.09h33.42v138.47h-38.38V65.23L496.19 109z"></path></svg></span></button><a href="/0NE_shoT_/items/08376b08783cd554b02e/likers" class="it-Footer_likeCount">72</a></div></div><div class="it-Footer_social"><div class="it-Footer_shareButton it-Footer_shareButton-twitter"><span class="fa fa-twitter"></span></div><div class="it-Footer_shareButton it-Footer_shareButton-facebook"><span class="fa fa-facebook"></span></div></div></div><div class="ai-Container"><div class="ai-User"><a href="/0NE_shoT_"><img src="https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fprofile-images%2F1526819848?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;lossless=0&amp;w=75&amp;s=8a125ec542a6b3dab2acaa64cee53a51" alt="0NE_shoT_" class="ai-User_image"/></a><div class="ai-User_body"><div class="ai-User_header"><a href="/0NE_shoT_" class="ai-User_name"></a><a href="/0NE_shoT_" class="ai-User_urlname">@<!-- -->0NE_shoT_</a></div><div class="ai-User_description">新人データ分析コンサルタントとして働いています。最近はWebマーケティングの意思決定の判断材料となるデータ分析をしています。</div><div class="ai-User_footer"><button class="UserFollowButton-sc-1hmm0rc-0 iytOeR">フォロー</button></div></div></div></div><div class="apm-Content"><div class="apm-Content_title">ユーザー登録して、Qiitaをもっと便利に使ってみませんか。</div><ol class="apm-Content_list"><li>あなたにマッチした記事をお届けします<div class="description">ユーザーやタグをフォローすることで、あなたが興味を持つ技術分野の情報をまとめてキャッチアップできます</div></li><li>便利な情報をあとで効率的に読み返せます<div class="description">気に入った記事を「ストック」することで、あとからすぐに検索できます</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>より詳しく</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">登録する</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">ログインする</a></div></div></div><div class="p-items_options"><div class="mt-2"></div></div><div class="p-items_toc"><div class="mt-2"></div></div></div></div><div class="p-items_wrapper p-items_wrapper-white"><div class="p-items_container"><div class="p-items_leftDummy"></div><div class="p-items_main"><div class="p-items_aside mt-5 px-5 p-2@s"><div id="logly-lift-4279493"><div class="tl-DummyItemList p-2"><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div></div></div></div><div class="p-items_aside mt-5 px-5 p-2@s"></div><div></div><div class="p-items_aside mt-6 px-5 p-2@s" id="comments-wrapper"><div id="comments" class="co-ItemWrapper"><div class="co-ItemWrapper_title mb-2"><span class="fa fa-comments mr-1"></span>コメント</div><div class="mb-4">この記事にコメントはありません。</div><div class="co-AnonymousForm p-3"><div class="co-AnonymousForm_title mb-1">あなたもコメントしてみませんか :)</div><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e&amp;realm=qiita" class="co-AnonymousForm_signup">ユーザ登録</a><div class="co-AnonymousForm_sub mt-1">すでにアカウントを持っている方は<a href="/login?callback_action=login_or_signup&amp;redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e&amp;realm=qiita" class="co-AnonymousForm_login">ログイン</a></div></div></div></div></div><div class="p-items_rightDummy"></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalArticlePage" data-dom-id="PersonalArticlePage-react-component-8dc18eb5-7cc1-49d0-a449-9a66b202c15b">{"article":{"body":"\n\u003ch1\u003e\n\u003cspan id=\"はじめに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eはじめに\u003c/h1\u003e\n\n\u003cp\u003e売り上げなどの数量（連続値をとる目的変数）を予測するのに役立つのが回帰です。この記事では、特に目的変数と説明変数の関係をモデル化する一つの方法である線形回帰をScikit-learnライブラリを使って行う方法について、備忘録として書いておきます。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"scikit-learn-について\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#scikit-learn-%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eScikit-learn について\u003c/h1\u003e\n\n\u003cp\u003eScikit-learnは、Pythonの機械学習ライブラリの一つです。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e公式ドキュメント：\u003ca href=\"http://scikit-learn.org/stable/index.html\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttp://scikit-learn.org/stable/index.html\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"線形回帰について\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e線形回帰について\u003c/h1\u003e\n\n\u003cp\u003e線形回帰は、連続値をとる目的変数 $y$ と説明変数 $x$（特徴量）の線形関係をモデル化します。線形関係とは、平たく言うと、説明変数が増加（減少）するのに応じて、目的変数も単調に増加（減少）する関係です。説明変数が一つの場合（単回帰と呼ぶ）、目的変数と説明変数の関係をモデル化する線形モデルは以下の式で定義されます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"math\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003ey = w_0 + w_1x\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eここで、重み $w_0$ は切片、重み $w_1$ は説明変数の係数を表します。線形回帰の目的は、説明変数と目的変数の関係を表現する線形モデルの重みを学習することです。上の式のように、目的変数が説明変数の一次式で表現されるとき、線形回帰は「説明変数と目的変数の散布図において、データの分布を最もよく特徴づける直線を探し出すこと」といえます。\u003c/p\u003e\n\n\u003cp\u003e説明変数が複数の場合（重回帰と呼ぶ）、目的変数を説明変数の線形和で表現する線形モデルは以下の式で定義されます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"math\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003ey = w_0x_0 + w_1x_1 + \\cdots +w_mx_m = \\sum^m_{i=0}w_ix_i\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eここで、重み $w_0$ は $x_0=1$ として切片を表します。重回帰は、単回帰を複数の説明変数を扱扱えるように一般化したものであり、目的変数と複数の説明変数の関係を表すモデルの重みを学習することが目的です。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"線形回帰モデル\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e線形回帰モデル\u003c/h1\u003e\n\n\u003cp\u003escikit-learnで線形回帰をするには、linear_modelのLinearRegressionモデル（公式ドキュメント：\u003ca href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttp://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\u003c/a\u003e ）を使います。主に利用するメソッドは以下の通りです。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003efitメソッド：線形モデルの重みを学習\u003c/li\u003e\n\u003cli\u003epredictメソッド：線形モデルから目的変数を予測\u003c/li\u003e\n\u003cli\u003escoreメソッド：決定係数（線形モデルがどの程度目的変数を説明できるか）を出力\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eここでは、UCI Machine Learning Repository (\u003ca href=\"http://archive.ics.uci.edu/ml/index.php\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttp://archive.ics.uci.edu/ml/index.php\u003c/a\u003e) で公開されている、ボストン市郊外の地域別住宅価格（\u003ca href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\u003c/a\u003e ）を使います。以下のコードでは、scikit-learnライブラリに付属のデータセットを読み込み、PandasのDataFrameに変換しています。（以降のコードの動作環境は、Python 3.7.3, pandas 0.24.2, scikit-learn 0.20.3 です。）\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_boston\u003c/span\u003e\n\u003cspan class=\"n\"\u003eboston\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_boston\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"c1\"\u003e# データセットの読み込み\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eboston\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboston\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 説明変数(boston.data)をDataFrameに保存\n\u003c/span\u003e\u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'MEDV'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboston\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 目的変数(boston.target)もDataFrameに追加\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eデータを覗いてみると、こんな感じです。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ehead\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=1d4e7b75cc95ebf4d871724e01beff26\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg width=\"514\" alt=\"boston.jpg\" src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=1d4e7b75cc95ebf4d871724e01beff26\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/258694/7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F7be59646-a3bb-5516-9b48-3cb4d2409351.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=76062d3516a0e2c412eb1ff7e548e3d2 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e各変数（データ項目）の説明は以下の通りです。\u003c/p\u003e\n\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align: left\"\u003e変数\u003c/th\u003e\n\u003cth style=\"text-align: left\"\u003e説明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eCRIM\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e犯罪発生率\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eZN\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e25,000平方フィート以上の住宅区画の割合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eINDUS\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e非小売業種の土地面積の割合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eCHAS\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003eチャールズ川沿いかを表すダミー変数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eNOX\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e窒素酸化物の濃度\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eRM\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e平均部屋数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eAGE\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e1940年より前に建てられた建物の割合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eDIS\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e5つのボストンの雇用施設への重み付き距離\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eRAD\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e高速道路へのアクセスのしやすさ\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eTAX\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e10,000ドルあたりの不動産税率\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003ePTRATIO\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e生徒と教師の割合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eB\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e黒人の割合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eLSTAT\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e低所得者の割合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eMEDV\u003c/td\u003e\n\u003ctd style=\"text-align: left\"\u003e住宅価格の中央値（1,000単位）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003cp\u003eここで、例えば以下のコードを使ってRM（平均部屋数）とMEDV（住宅価格）の関係を見てみると、おおむね線形関係にある、つまり平均部屋数が多いほど住宅価格も高いように見えます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ematplotlib.pyplot\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eplt\u003c/span\u003e\n\u003cspan class=\"o\"\u003e%\u003c/span\u003e\u003cspan class=\"n\"\u003ematplotlib\u003c/span\u003e \u003cspan class=\"n\"\u003einline\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003escatter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'RM'\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'MEDV'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 平均部屋数と住宅価格の散布図をプロット\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Scatter Plot of RM vs MEDV'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# 図のタイトル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exlabel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Average number of rooms [RM]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# x軸のラベル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eylabel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Prices in $1000\u003c/span\u003e\u003cspan class=\"si\"\u003e\\\u003c/span\u003e\u003cspan class=\"se\"\u003e'\u003c/span\u003e\u003cspan class=\"s\"\u003es [MEDV]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# y軸のラベル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egrid\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e                                 \u003cspan class=\"c1\"\u003e# グリッド線を表示\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e                                 \u003cspan class=\"c1\"\u003e# 図の表示\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=c097a18be2bc1723e49bf5d814e36043\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=c097a18be2bc1723e49bf5d814e36043\" alt=\"scatter_plot2.jpg\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/258694/6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F6ce7eecc-bff3-6c91-fe6d-077e44bf00b4.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=8c5775ad961b380240a925063394380c 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003ePandasのcorr()メソッドで平均部屋数と住宅価格の相関係数を算出してみると、約0.7程度と正の相関があることがわかります。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"s\"\u003e'RM'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"s\"\u003e'MEDV'\u003c/span\u003e\u003cspan class=\"p\"\u003e]].\u003c/span\u003e\u003cspan class=\"n\"\u003ecorr\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=680bdd7355a9c7fd8f29c16ebe520989\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg width=\"124\" alt=\"corr.jpg\" src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=680bdd7355a9c7fd8f29c16ebe520989\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/258694/8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8f20fecc-f175-ef90-c418-d51bb829ffda.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=64d4d4059ff78cc26167418aae52cf9d 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e以降では、住宅価格（目的変数）と平均部屋数（説明変数）の関係を表現する線形回帰モデルを構築してみます。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"線形回帰モデルの構築\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e線形回帰モデルの構築\u003c/h1\u003e\n\n\u003cp\u003efitメソッドで重みを学習することで、線形回帰モデルを構築します。学習の際には、説明変数Xと目的変数YにはNumpyの配列を利用するため、values属性で説明変数と目的変数の列からNumpyの配列を取り出しています。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.linear_model\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eLinearRegression\u003c/span\u003e\n\u003cspan class=\"n\"\u003elr\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eLinearRegression\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"s\"\u003e'RM'\u003c/span\u003e\u003cspan class=\"p\"\u003e]].\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e         \u003cspan class=\"c1\"\u003e# 説明変数（Numpyの配列）\n\u003c/span\u003e\u003cspan class=\"n\"\u003eY\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'MEDV'\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e         \u003cspan class=\"c1\"\u003e# 目的変数（Numpyの配列）\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e                         \u003cspan class=\"c1\"\u003e# 線形モデルの重みを学習\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e学習により得られた、線形モデルの切片 $w_0$ はintercept_属性に、説明変数の係数 $w_1$ はcoef_属性に格納されます。学習結果を確認すると、係数は約9.1、切片は約-34.7であることがわかります。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'coefficient = '\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecoef_\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 説明変数の係数を出力\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'intercept = '\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eintercept_\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 切片を出力\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003ecoefficient\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e  \u003cspan class=\"mf\"\u003e9.10210898118\u003c/span\u003e\n\u003cspan class=\"n\"\u003eintercept\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e  \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mf\"\u003e34.6706207764\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e学習で得られた切片と係数を利用して、回帰直線を引いてみます。回帰直線をプロットするには、線形モデルに説明変数の値を与えたときの目的変数の値（予測値）が必要になります。以下のコードでは、これを得るためにpredictメソッドを利用しています。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003escatter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'blue'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e         \u003cspan class=\"c1\"\u003e# 説明変数と目的変数のデータ点の散布図をプロット\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eplot\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'red'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 回帰直線をプロット\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Regression Line'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e               \u003cspan class=\"c1\"\u003e# 図のタイトル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exlabel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Average number of rooms [RM]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# x軸のラベル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eylabel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Prices in $1000\u003c/span\u003e\u003cspan class=\"si\"\u003e\\\u003c/span\u003e\u003cspan class=\"se\"\u003e'\u003c/span\u003e\u003cspan class=\"s\"\u003es [MEDV]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# y軸のラベル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egrid\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e                                 \u003cspan class=\"c1\"\u003e# グリッド線を表示\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e                                 \u003cspan class=\"c1\"\u003e# 図の表示\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e与えられたデータ点にある程度フィットした回帰直線を引くことができていることが確認できます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=6280e94d1460ef7bdafe8021b262e078\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=6280e94d1460ef7bdafe8021b262e078\" alt=\"regression_line.jpg\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/258694/8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2F8ff6e456-c348-21fd-42ac-4889fc0e0cc7.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=ea36559a71b2bde0ef6d0b2cb834da9d 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"線形回帰モデルの性能評価\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%80%A7%E8%83%BD%E8%A9%95%E4%BE%A1\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e線形回帰モデルの性能評価\u003c/h1\u003e\n\n\u003cp\u003e学習により得られた線形モデルの性能を評価するには、学習には用いていないデータでモデルを検証することが必要です。構築したモデルを今後利用する（例：売上予測モデルの予測結果を使ってビジネス計画を策定する・なんらかの施策を打っていく）ことを考慮すると、モデル構築時には得られない将来のデータに対して精度よく予測できることが重要であるためです。そのためには、まず手元のデータを学習データと検証データに分けます。そして、学習データでモデルを構築し、検証データを将来のデータと見立て、これに対するモデルの性能（汎化性能と呼ぶ）を評価します。\u003c/p\u003e\n\n\u003cp\u003e以下のコードでは、model_selectionのtrain_test_split（公式ドキュメント：\u003ca href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttp://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\u003c/a\u003e ）を利用して、データを学習用と検証用に7:3の割合で分割し、学習データを用いて線形モデルを構築しています。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.model_selection\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003etrain_test_split\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX_train\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eX_test\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_train\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_test\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etrain_test_split\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etrain_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.7\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etest_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# データを学習用と検証用に分割\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003elr\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eLinearRegression\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX_train\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_train\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 線形モデルの重みを学習\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e線形回帰モデルの性能評価には、主に以下の方法・指標を利用します。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e残差プロット：残差（目的変数の真値と予測値の差分）を可視化\u003c/li\u003e\n\u003cli\u003e平均二乗誤差：残差平方和をデータ数で正規化した値\u003c/li\u003e\n\u003cli\u003e決定係数：相関係数の二乗\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e残差プロットは、残差（目的変数の真値と予測値の差分）の分布を可視化したものです。線形モデルが目的変数を完璧に予測できる場合は残差は0となるので、予測精度の良い線形モデルの残差プロットは、0を中心にランダムにばらついたものになります。残差プロットに何かパターンが見られる場合は、線形モデルで説明しきれない情報があることが示唆されます。以下のコードは、残差プロットを描画します。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"n\"\u003eY_pred\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX_test\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 検証データを用いて目的変数を予測\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003escatter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eY_pred\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_pred\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003eY_test\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'blue'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e      \u003cspan class=\"c1\"\u003e# 残差をプロット \n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ehlines\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003exmin\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003exmax\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e50\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'black'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# x軸に沿った直線をプロット\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Residual Plot'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e                                \u003cspan class=\"c1\"\u003e# 図のタイトル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exlabel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Predicted Values'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e                            \u003cspan class=\"c1\"\u003e# x軸のラベル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eylabel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'Residuals'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e                                   \u003cspan class=\"c1\"\u003e# y軸のラベル\n\u003c/span\u003e\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egrid\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e                                                \u003cspan class=\"c1\"\u003e# グリッド線を表示\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eplt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e                                               \u003cspan class=\"c1\"\u003e# 図の表示\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e残差プロットを見てみると、残差は0を中心に分布していますが、線形モデルで説明しきれないパターンもあるように見えます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fce893435-4080-ac48-abe7-baef1a3bd010.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=05e4f7d40b758432b3c8bdce62ec822a\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fce893435-4080-ac48-abe7-baef1a3bd010.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=05e4f7d40b758432b3c8bdce62ec822a\" alt=\"residual_plot.jpg\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/258694/ce893435-4080-ac48-abe7-baef1a3bd010.jpeg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fce893435-4080-ac48-abe7-baef1a3bd010.jpeg?ixlib=rb-1.2.2\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=55c6e55396fb51754dff2fa2eede8474 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e平均二乗誤差は、残差の平方和をデータ数で正規化したものであり、モデルの性能を数値化するのに役立ちます。もちろん、誤差が小さいほどモデルの性能は良いといえます。平均二乗誤差は、metricsのmean_squared_errorを利用することで算出できます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.metrics\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003emean_squared_error\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eY_train_pred\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX_train\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 学習データに対する目的変数を予測\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'MSE train data: '\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emean_squared_error\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eY_train\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_train_pred\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 学習データを用いたときの平均二乗誤差を出力\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'MSE test data: '\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emean_squared_error\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eY_test\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_pred\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e         \u003cspan class=\"c1\"\u003e# 検証データを用いたときの平均二乗誤差を出力\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e学習データ、検証データそれぞれを用いたときの平均二乗誤差を比較すると、検証データを用いたときの誤差の方が大きいことがわかります。このことから、構築した線形モデルは学習データにフィットしすぎている（過学習と呼ぶ）ことが示唆されます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"n\"\u003eMSE\u003c/span\u003e \u003cspan class=\"n\"\u003etrain\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e  \u003cspan class=\"mf\"\u003e42.1576508631\u003c/span\u003e\n\u003cspan class=\"n\"\u003eMSE\u003c/span\u003e \u003cspan class=\"n\"\u003etest\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e  \u003cspan class=\"mf\"\u003e47.0330474798\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e決定係数も、線形モデルの予測誤差を反映した指標であり、値が大きいほど線形モデルがデータにフィットしているといえます。決定係数は、metricsのr2_scoreを利用することで算出できます。また、LinearRegressionモデルのscoreメソッドでも算出できます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.metrics\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003er2_score\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'r^2 train data: '\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003er2_score\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eY_train\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_train_pred\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'r^2 test data: '\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003er2_score\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eY_test\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY_pred\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e学習データ、検証データそれぞれを用いたときの決定係数を比較すると、検証データを用いたときの決定係数の方が小さいことがわかります。このことからも、構築した線形モデルには過学習が起こっている可能性があることがわかります。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"Python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"o\"\u003e^\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e \u003cspan class=\"n\"\u003etrain\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e  \u003cspan class=\"mf\"\u003e0.502649763004\u003c/span\u003e\n\u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"o\"\u003e^\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e \u003cspan class=\"n\"\u003etest\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e  \u003cspan class=\"mf\"\u003e0.435143648321\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eここまでは単回帰のコード例を示してきましたが、重回帰の場合も簡単に試すことができます。\u003cbr\u003e\n例えば、住宅価格（目的変数）と、平均部屋数および低所得者の割合（説明変数）の関係を表現する線形回帰モデルは、以下のようなコードで構築することができます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"n\"\u003elr\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eLinearRegression\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"s\"\u003e'RM'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e'LSTAT'\u003c/span\u003e\u003cspan class=\"p\"\u003e]].\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e         \u003cspan class=\"c1\"\u003e# 説明変数（Numpyの配列）\n\u003c/span\u003e\u003cspan class=\"n\"\u003eY\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboston_df\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'MEDV'\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e         \u003cspan class=\"c1\"\u003e# 目的変数（Numpyの配列）\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003elr\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e                         \u003cspan class=\"c1\"\u003e# 線形モデルの重みを学習\n\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"おわりに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eおわりに\u003c/h1\u003e\n\n\u003cp\u003eこの記事では、scikit-learnライブラリで線形回帰をする方法について簡単に触れました。目的変数をより精度よく表現する線形モデルを構築するためには、特徴量（説明変数）選択や正則化を行うことを検討する必要がありますが、その点についても今後まとめてみようと思います。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"参考\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e参考\u003c/h1\u003e\n\n\u003cul\u003e\n\u003cli\u003e[第2版]Python機械学習プログラミング 達人データサイエンティストによる理論と実装（\u003ca href=\"https://www.amazon.co.jp/dp/B07BF5QZ41/ref=dp-kindle-redirect?_encoding=UTF8\u0026amp;btkr=1\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttps://www.amazon.co.jp/dp/B07BF5QZ41/ref=dp-kindle-redirect?_encoding=UTF8\u0026amp;btkr=1\u003c/a\u003e ）\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"更新履歴\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%9B%B4%E6%96%B0%E5%B1%A5%E6%AD%B4\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e更新履歴\u003c/h1\u003e\n\n\u003cul\u003e\n\u003cli\u003e（2019/12/30）重回帰のコード例の追記\u003c/li\u003e\n\u003c/ul\u003e\n","createdAt":"2018-06-11T14:40:10Z","elapsedYearsFromUpdatedAt":0,"encryptedId":"qV0q5QyvobcI3W8g8468Y25qMkXxzJ8v--v6GlIqm6lHey71gj--WWNYaJo2HKcEjwxfrclgRw==","isBanned":false,"isDeprecated":false,"isDestroyableByViewer":false,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isUpdatableByViewer":false,"isSubscribableByViewer":false,"isSubscribedByViewer":false,"isUpdated":true,"likesCount":72,"originalId":656715,"title":"Scikit-learn で線形回帰","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"\u003eはじめに\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#scikit-learn-%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003eScikit-learn について\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003e線形回帰について\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB\"\u003e線形回帰モデル\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89\"\u003e線形回帰モデルの構築\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%80%A7%E8%83%BD%E8%A9%95%E4%BE%A1\"\u003e線形回帰モデルの性能評価\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB\"\u003eおわりに\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e参考\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%9B%B4%E6%96%B0%E5%B1%A5%E6%AD%B4\"\u003e更新履歴\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","totalPv":44185,"updatedAt":"2019-12-30T08:14:55Z","uuid":"08376b08783cd554b02e","banReason":null,"adventCalendarItem":null,"author":{"originalId":258694,"description":"新人データ分析コンサルタントとして働いています。最近はWebマーケティングの意思決定の判断材料となるデータ分析をしています。","name":"","profileImageUrl":"https://qiita-image-store.s3.amazonaws.com/0/258694/profile-images/1526819848","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fprofile-images%2F1526819848?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=34cb790dd8c26a62da1ffb147b11d45a","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F258694%2Fprofile-images%2F1526819848?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=8a125ec542a6b3dab2acaa64cee53a51","urlName":"0NE_shoT_","isBlockingViewer":false,"isFollowedByViewer":false,"isFollowableByViewer":true,"websiteUrl":"","organizations":{"edges":[]}},"tags":[{"name":"Python","urlName":"python"},{"name":"機械学習","urlName":"%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92"},{"name":"scikit-learn","urlName":"scikit-learn"}],"followingLikers":{"edges":[]},"comments":{"totalCount":1},"organization":null},"viewer":null,"analyticsTrackingId":null}</script>
      
<script src="//d-cache.microad.jp/js/td_qt_access.js" type="text/javascript"></script><script>microadTd.QT.start({"article_category": "Python,機械学習,scikit-learn"})</script><script>(function(d,u){var b=d.getElementsByTagName("script")[0],j=d.createElement("script");j.async=true;j.src=u;b.parentNode.insertBefore(j,b);})(document,"//img.ak.impact-ad.jp/ut/ff9a3577423c8ed5_4330.js");</script><noscript><iframe frameborder="0" height="0" src="//nspt.unitag.jp/ff9a3577423c8ed5_4330.php" width="0"></iframe></noscript><script async="" src="https://www.googletagmanager.com/gtag/js?id=AW-878053044"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'AW-878053044');</script><script>!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window, document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '1792588824374455');
fbq('track', 'PageView');</script><noscript><img height="1" src="https://www.facebook.com/tr?id=1792588824374455&amp;ev=PageView&amp;noscript=1" style="display:none" width="1" /></noscript><footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">利用規約</a><a href="/privacy">プライバシー</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">ガイドライン</a><a href="/release-notes">リリース</a></div><div class="st-Footer_column"><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">ヘルプ</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">広告掲載</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">ブログ</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2020 Increments Inc.</div></footer><div id="Snackbar-react-component-29c20439-a1bf-4b83-9472-6c5a97889e1e"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-29c20439-a1bf-4b83-9472-6c5a97889e1e">{}</script>
      
<div id="LoginModal-react-component-470bd8d0-29cd-49be-b9c9-96c4bc5a7d37"><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body lm-Dialog"><div class="fa fa-times lm-Dialog_close"></div><div class="lm-Dialog_title">ユーザー登録して、Qiitaをもっと便利に使ってみませんか。</div><div class="lm-Dialog_message-pc">この機能を利用するにはログインする必要があります。ログインするとさらに便利にQiitaを利用できます。</div><div class="lm-Dialog_message-mobile">この機能を利用するにはログインする必要があります。ログインするとさらに便利にQiitaを利用できます。</div><ol class="lm-Dialog_list"><li>あなたにマッチした記事をお届けします<div class="description">ユーザーやタグをフォローすることで、あなたが興味を持つ技術分野の情報をまとめてキャッチアップできます</div></li><li>便利な情報をあとで効率的に読み返せます<div class="description">気に入った記事を「ストック」することで、あとからすぐに検索できます</div></li></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e&amp;realm=qiita" class="lm-Dialog_button lm-Dialog_button-signup">登録する</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2F0NE_shoT_%2Fitems%2F08376b08783cd554b02e&amp;realm=qiita" class="lm-Dialog_button lm-Dialog_button-signin">ログインする</a></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-470bd8d0-29cd-49be-b9c9-96c4bc5a7d37">{}</script>
      
<div id="UserHoverCard-react-component-6aac0f50-6b02-4508-95ec-9015e90ff8bd"><div class="uh-Container" style="left:0px;top:0px"><div>ユーザーは見つかりませんでした</div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="UserHoverCard" data-dom-id="UserHoverCard-react-component-6aac0f50-6b02-4508-95ec-9015e90ff8bd">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;IW85b/Cd3VZr2H2SrKSSpN91gKQDUTX0w+nThiJcNlqX7OxRXlPmCgqmkR15S05/FXhxNSYkjN7wAAGzGxVtAw==&quot;,&quot;locale&quot;:&quot;ja&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStore">{"snackbar":{"type":"","body":"","isActive":false}}</script>